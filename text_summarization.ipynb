{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of [homework]text_summarization_solved.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QsAcVSli3r3S"
      ],
      "toc_visible": true
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0052114ec3024935b1b0d55e8e2f06a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20883e0fd7134502820cbcdfa47d7d47",
              "IPY_MODEL_b0739676ae924a55afc4b710cadca232"
            ],
            "layout": "IPY_MODEL_f2c3a3857c1548d4a68c222a07299d11"
          }
        },
        "f2c3a3857c1548d4a68c222a07299d11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20883e0fd7134502820cbcdfa47d7d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0a6566ed97c40c8a00f74b8411681a1",
            "max": 52400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5e7f49112d4428f9c1f9398773487d1",
            "value": 52400
          }
        },
        "b0739676ae924a55afc4b710cadca232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a753d198d69438aa7a8f0174e404b33",
            "placeholder": "​",
            "style": "IPY_MODEL_2555db731bb340c880369a1866cb7de3",
            "value": " 52400/52400 [27:12&lt;00:00, 32.09it/s]"
          }
        },
        "b5e7f49112d4428f9c1f9398773487d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "a0a6566ed97c40c8a00f74b8411681a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2555db731bb340c880369a1866cb7de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a753d198d69438aa7a8f0174e404b33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2c32cbb5e76493eaf157a729e4945e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b72ccfd428e4aabb9f3f52727bf536b",
              "IPY_MODEL_294f6101a1fb4e66b4ed90946877165d"
            ],
            "layout": "IPY_MODEL_c296a36415c24ae99385cde72ad1a1a1"
          }
        },
        "c296a36415c24ae99385cde72ad1a1a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b72ccfd428e4aabb9f3f52727bf536b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc689ade0a7e4a2296a5abcffd6caaee",
            "max": 5770,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d0dc70b20f54f46a2483dede6f67c82",
            "value": 5770
          }
        },
        "294f6101a1fb4e66b4ed90946877165d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c7d010a9a884054b57d32c54baf004e",
            "placeholder": "​",
            "style": "IPY_MODEL_885bf4db1c4b44c5a0991ac930e5a2c3",
            "value": " 5770/5770 [18:43&lt;00:00,  5.14it/s]"
          }
        },
        "1d0dc70b20f54f46a2483dede6f67c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "cc689ade0a7e4a2296a5abcffd6caaee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "885bf4db1c4b44c5a0991ac930e5a2c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c7d010a9a884054b57d32c54baf004e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03d9bf261d004f42a670d5d48af74dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_07f11d207f694a1c9dd3b9ef4eca2481",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_17aca299d82b4d04b98c569ef439e388",
              "IPY_MODEL_63ff5d22e2f04c718a75b53736fedaf8"
            ]
          }
        },
        "07f11d207f694a1c9dd3b9ef4eca2481": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17aca299d82b4d04b98c569ef439e388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c84df55980af4f28a6868f3844fecde7",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 500,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 500,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b27cae5003554d6787a883877c4bc1fc"
          }
        },
        "63ff5d22e2f04c718a75b53736fedaf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a1d8f749f19f4c9380915805d0fdbc6c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 500/500 [00:22&lt;00:00, 22.65it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be3beace13f8465191ce20ef343923fb"
          }
        },
        "c84df55980af4f28a6868f3844fecde7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b27cae5003554d6787a883877c4bc1fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1d8f749f19f4c9380915805d0fdbc6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be3beace13f8465191ce20ef343923fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Kmb8UhIzOnfK"
      },
      "source": [
        "# Text Summarization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j0iXf5g8WN7F",
        "outputId": "40e98a3b-2442-4367-8891-0f8602fe5f97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SXS1sdYZCluU",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "pip install --upgrade pandas --force-reinstall\n",
        "pip install -U spacy==2.2.4 requests==2.23.0 folium==0.2.1\n",
        "pip install -U nltk==3.4.5 rouge==0.3.1\n",
        "pip install --upgrade razdel fasttext networkx\n",
        "pip install --upgrade torch transformers catalyst pymorphy2 pymorphy2-dicts-ru\n",
        "pip install --upgrade deeppavlov"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UqSU5bYa5Kd9",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import copy\n",
        "from itertools import combinations\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "from scipy.spatial import distance\n",
        "import networkx as nx\n",
        "import fasttext\n",
        "import razdel\n",
        "import nltk, pymorphy2\n",
        "\n",
        "import torch, catalyst, transformers\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "from torch.utils import data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import CyclicLR\n",
        "\n",
        "import catalyst\n",
        "from catalyst.dl.runner import SupervisedRunner\n",
        "from catalyst.core.callbacks.early_stop import EarlyStoppingCallback\n",
        "\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from rouge import Rouge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_rsGi3cNUhCO",
        "colab": {}
      },
      "source": [
        "from deeppavlov.core.common.file import read_json\n",
        "from deeppavlov import build_model, configs\n",
        "from deeppavlov.models.embedders.elmo_embedder import ELMoEmbedder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KzoMQXr0SSrc",
        "outputId": "c79a15b7-7560-4aaf-ff0d-617c25cae02b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OqkLTkFRfXvA",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "wget -q https://www.dropbox.com/s/43l702z5a5i2w8j/gazeta_train.txt\n",
        "wget -q https://www.dropbox.com/s/k2egt3sug0hb185/gazeta_val.txt\n",
        "wget -q https://www.dropbox.com/s/3gki5n5djs9w0v6/gazeta_test.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5pZ2UGS2DGjH",
        "colab": {}
      },
      "source": [
        "def read_gazeta_records(file_name, shuffle=True, sort_by_date=False):\n",
        "    assert shuffle != sort_by_date\n",
        "    records = []\n",
        "    with open(file_name, \"r\") as r:\n",
        "        for line in r:\n",
        "            records.append(eval(line)) # Simple hack\n",
        "    records = pd.DataFrame(records)\n",
        "    if sort_by_date:\n",
        "        records = records.sort(\"date\")\n",
        "    if shuffle:\n",
        "        records = records.sample(frac=1)\n",
        "    return records"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GNDp-BunEA91",
        "colab": {}
      },
      "source": [
        "train_records = read_gazeta_records(\"gazeta_train.txt\")\n",
        "val_records = read_gazeta_records(\"gazeta_val.txt\")\n",
        "test_records = read_gazeta_records(\"gazeta_test.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2YhLOIRnB6sJ",
        "outputId": "8984eaef-f489-4f97-d355-ced61613437e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(train_records.shape, test_records.shape, val_records.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((52400, 5), (5770, 5), (5265, 5))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WycaVkq3CJLs",
        "colab": {}
      },
      "source": [
        "# check empty records\n",
        "def check_empty(records):\n",
        "    for idx, row in records.iterrows():\n",
        "        try:\n",
        "            if not (len(row['text']) and len(row['summary'])):\n",
        "                print(row['text'], row['summary'])\n",
        "            except AttributeError:\n",
        "                  print(f'Empty object found at {idx}!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d-0MUm2pDu4t",
        "colab": {}
      },
      "source": [
        "check_empty(train_records)\n",
        "check_empty(val_records)\n",
        "check_empty(test_records)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OsWHgn9wI4rQ",
        "colab": {}
      },
      "source": [
        "# get average text len (# sentences), sentence len (# words)\n",
        "def avg_text_sum_len(records):\n",
        "    text_len = 0; sum_len = 0\n",
        "    text_words = 0; sum_words = 0\n",
        "    for text, summary in tqdm(records[['text', 'summary']].values):\n",
        "        text_sent = [sent.text for sent in razdel.sentenize(text)]\n",
        "        sum_sent = [sent.text for sent in razdel.sentenize(summary)]\n",
        "        text_len += len(text_sent)\n",
        "        sum_len += len(sum_sent)\n",
        "        text_words += np.max([len(list(razdel.tokenize(sent))) for sent in text_sent])\n",
        "        sum_words += np.max([len(list(razdel.tokenize(sent))) for sent in sum_sent])\n",
        "    n = records.shape[0]\n",
        "    text_len /= n; sum_len /= n\n",
        "    text_words /= n; sum_words /= n\n",
        "    return text_len, text_words, sum_len, sum_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9hYgNpxvPmR0",
        "outputId": "26a6caf5-c0f2-48b6-95b1-e7a284fa97ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "0052114ec3024935b1b0d55e8e2f06a8",
            "f2c3a3857c1548d4a68c222a07299d11",
            "20883e0fd7134502820cbcdfa47d7d47",
            "b0739676ae924a55afc4b710cadca232",
            "b5e7f49112d4428f9c1f9398773487d1",
            "a0a6566ed97c40c8a00f74b8411681a1",
            "2555db731bb340c880369a1866cb7de3",
            "7a753d198d69438aa7a8f0174e404b33"
          ]
        }
      },
      "source": [
        "avg_text_sum_len(train_records)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0052114ec3024935b1b0d55e8e2f06a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=52400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37.24198473282443, 50.627614503816794, 2.656583969465649, 24.981068702290077)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ml-0lj_HLff5",
        "colab": {}
      },
      "source": [
        "def calc_scores(references, predictions, metric=\"all\"):\n",
        "    print(\"Count:\", len(predictions))\n",
        "    print(\"Ref:\", references[-1])\n",
        "    print(\"Hyp:\", predictions[-1])\n",
        "\n",
        "    if metric in (\"bleu\", \"all\"):\n",
        "        print(\"BLEU: \", corpus_bleu([[r] for r in references], predictions))\n",
        "    if metric in (\"rouge\", \"all\"):\n",
        "        rouge = Rouge()\n",
        "        scores = rouge.get_scores(predictions, references, avg=True)\n",
        "        print(\"ROUGE: \", scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QsAcVSli3r3S"
      },
      "source": [
        "## TextRank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3axu2qRNIWjx",
        "colab": {}
      },
      "source": [
        "def gen_text_rank_summary(text, calc_sim, summary_part=0.1, lower=True, \n",
        "                          tokenize=True, morph=None, model=None, get_vecs_f=None):\n",
        "    # split text\n",
        "    sentences = [sentence.text.lower() if lower else sentence.text \\\n",
        "                 for sentence in razdel.sentenize(text)]\n",
        "    n_sentences = len(sentences)\n",
        "\n",
        "    # tokenization\n",
        "    if tokenize:\n",
        "        sent_words = [[token.text.lower() if lower else token.text \\\n",
        "                       for token in razdel.tokenize(sentence)] for sentence in sentences]\n",
        "    else:\n",
        "        sent_words = sentences\n",
        "\n",
        "    # lemmatization\n",
        "    if morph is not None:\n",
        "        sent_words = [[morph.parse(word)[0].normal_form for word in words] \\\n",
        "                           for words in sent_words]\n",
        "\n",
        "    # pairwise sentence similarity\n",
        "    pairs = combinations(range(n_sentences), 2)\n",
        "    if model is not None and get_vecs_f is not None:\n",
        "        sent_words = get_vecs_f(model, sent_words)\n",
        "    scores = [(i, j, calc_sim(sent_words[i], sent_words[j])) for i, j in pairs]\n",
        "\n",
        "    # weighted graph with similarity scores\n",
        "    g = nx.Graph()\n",
        "    g.add_weighted_edges_from(scores)\n",
        "\n",
        "    # PageRank\n",
        "    pr = nx.pagerank(g)\n",
        "    result = [(i, pr[i], s) for i, s in enumerate(sentences) if i in pr]\n",
        "    result.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # choose top sent\n",
        "    n_summary_sentences = max(int(n_sentences * summary_part), 1)\n",
        "    result = result[:n_summary_sentences]\n",
        "\n",
        "    # restore original sent order\n",
        "    result.sort(key=lambda x: x[0])\n",
        "\n",
        "    # restore summary text\n",
        "    predicted_summary = \" \".join([sentence for i, proba, sentence in result])\n",
        "    predicted_summary = predicted_summary.lower() if lower else predicted_summary\n",
        "    return predicted_summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m2GwyRrMPAzS",
        "colab": {}
      },
      "source": [
        "def calc_text_rank_score(records, calc_sim, summary_part=0.1, lower=True, tokenize=True, \n",
        "                         nrows=1000, morph=None, model=None, get_vecs_f=None):\n",
        "    references = []\n",
        "    predictions = []\n",
        "\n",
        "    for text, summary in records[['text', 'summary']].values[:nrows]:\n",
        "        summary = summary if not lower else summary.lower()\n",
        "        references.append(summary)\n",
        "\n",
        "        predicted_summary = gen_text_rank_summary(text, calc_sim, summary_part, \n",
        "                                                  lower, tokenize, morph=morph, \n",
        "                                                  model=model, \n",
        "                                                  get_vecs_f=get_vecs_f)\n",
        "        text = text if not lower else text.lower()\n",
        "        predictions.append(predicted_summary)\n",
        "\n",
        "    calc_scores(references, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "78ADO9wPBugq"
      },
      "source": [
        "### Similarity based on words intersection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tZjFFk84IPgr",
        "colab": {}
      },
      "source": [
        "def unique_words_sim(words1, words2):\n",
        "    words1 = set(words1)\n",
        "    words2 = set(words2)\n",
        "    if not len(words1) or not len(words2):\n",
        "        return 0.0\n",
        "    return len(words1.intersection(words2))/(np.log10(len(words1)) + np.log10(len(words2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fhXPtSCeAStf",
        "outputId": "fe83867a-0868-4ac7-93e3-dee61e810cbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "calc_text_rank_score(test_records, calc_sim=unique_words_sim)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count: 1000\n",
            "Ref: в крыму заявили, что угрозы украинских властей отреагировать на запуск поездов по крымскому мосту являются попыткой вмешательства во внутренние дела россии. при этом власти полуострова напомнили, что такие обещания киева пустые, и, как правило, не влекут никаких последствий.\n",
            "Hyp: по его словам, подобные обещания, как были высказаны так называемым «представителем президента украины в крыму» антоном кориневичем, являются голословными и вряд ли представляют реальную угрозу для моста через керченский пролив, передает rt. доехать на именных поездах «таврия» из москвы до симферополя в купе можно будет за 2966 руб., а из санкт-петербурга до севастополя — за 3906 руб. «пять одноэтажных поездов, состоящих из купейных и плацкартных вагонов выведут на маршрут, который соединит северную столицу россии с севастополем», — говорится в сообщении перевозчика.\n",
            "BLEU:  0.27401385077499585\n",
            "ROUGE:  {'rouge-1': {'f': 0.15987203393568736, 'p': 0.13245879938563265, 'r': 0.21737094280809163}, 'rouge-2': {'f': 0.03619451964714865, 'p': 0.02940511392295411, 'r': 0.051414679328173084}, 'rouge-l': {'f': 0.1262042011722298, 'p': 0.11723326378496897, 'r': 0.1927653483840329}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HB8U09qnCBXg"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "### Cosine similarity with pretrained embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IHJx1BNFIQ7j",
        "colab": {}
      },
      "source": [
        "def cosine_sim(s1, s2):\n",
        "    return 1 - distance.cosine(s1, s2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Qw6MWvGqezRO"
      },
      "source": [
        "#### FastText Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lHgWGx4qIUCY",
        "colab": {}
      },
      "source": [
        "def get_ft_embeddings(model, sent_words):\n",
        "    sent_vecs = []\n",
        "    for sent in sent_words:\n",
        "        word_vecs = [model.get_word_vector(word) for word in sent]\n",
        "        sent_vecs.append(np.mean(word_vecs, axis=0))\n",
        "    return sent_vecs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lC-b_OLAAjNv",
        "colab": {}
      },
      "source": [
        "ft = fasttext.load_model('drive/My Drive/ft_lem.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P-8LNPZe8fOR",
        "colab": {}
      },
      "source": [
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ydo8iuIVIr7l",
        "outputId": "5cd02b8c-f9f8-41dd-878f-c30d329f3678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "calc_text_rank_score(test_records, calc_sim=cosine_sim, model=ft, \n",
        "                     get_vecs_f=get_ft_embeddings, morph=morph)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count: 1000\n",
            "Ref: в крыму заявили, что угрозы украинских властей отреагировать на запуск поездов по крымскому мосту являются попыткой вмешательства во внутренние дела россии. при этом власти полуострова напомнили, что такие обещания киева пустые, и, как правило, не влекут никаких последствий.\n",
            "Hyp: уже в следующем году, когда появится стабильное расписание, люди из всех уголков нашей страны смогут заранее планировать поездки в крым. севастопольцы очень ждут запуска поездов, чтобы заранее планировать свои поездки в столицу и другие регионы», — заверил глава города федерального значения. стоит отметить, что чуть ранее глава республики крым сергей аксенов заявил: инфраструктура полуострова полностью готова к возобновлению железнодорожного сообщения с украиной, теперь решение остается только за киевом.\n",
            "BLEU:  0.2676917384164895\n",
            "ROUGE:  {'rouge-1': {'f': 0.15266251535370307, 'p': 0.12352676093801424, 'r': 0.2153909542432146}, 'rouge-2': {'f': 0.03135829505675102, 'p': 0.02519721936393644, 'r': 0.04509112778090324}, 'rouge-l': {'f': 0.11861558724298146, 'p': 0.109645786279101, 'r': 0.19127099456673688}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2S6eDTiL8UPg"
      },
      "source": [
        "#### ELMo Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "01r52K0hZ62N",
        "colab": {}
      },
      "source": [
        "def get_elmo_embeddings(model, sent_words):\n",
        "    return model(sent_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L_sfZCmaKuWU",
        "colab": {}
      },
      "source": [
        "elmo = ELMoEmbedder('http://files.deeppavlov.ai/deeppavlov_data/elmo_ru-news_wmt11-16_1.5M_steps.tar.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2C124RfnapCE",
        "outputId": "2066711f-c23d-4cd6-eaa5-349031b61a30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "calc_text_rank_score(test_records, calc_sim=cosine_sim, model=elmo, \n",
        "                     get_vecs_f=get_elmo_embeddings, tokenize=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count: 1000\n",
            "Ref: в крыму заявили, что угрозы украинских властей отреагировать на запуск поездов по крымскому мосту являются попыткой вмешательства во внутренние дела россии. при этом власти полуострова напомнили, что такие обещания киева пустые, и, как правило, не влекут никаких последствий.\n",
            "Hyp: кроме того, сенатор предположил, что возможность добраться до полуострова на поезде значительно увеличит количество отдыхающих в крыму. севастопольцы очень ждут запуска поездов, чтобы заранее планировать свои поездки в столицу и другие регионы», — заверил глава города федерального значения. стоит отметить, что чуть ранее глава республики крым сергей аксенов заявил: инфраструктура полуострова полностью готова к возобновлению железнодорожного сообщения с украиной, теперь решение остается только за киевом.\n",
            "BLEU:  0.2936942520323366\n",
            "ROUGE:  {'rouge-1': {'f': 0.15978593060486648, 'p': 0.1366146967958347, 'r': 0.20728347462094615}, 'rouge-2': {'f': 0.03369622113710133, 'p': 0.028526382895340662, 'r': 0.04456106375186457}, 'rouge-l': {'f': 0.12942405127417725, 'p': 0.12213980673557023, 'r': 0.18487645851029583}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F1MC4uI638EZ"
      },
      "source": [
        "#### RuBERT Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xDtIQeZw11Te",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "wget -O rubert_sent.tar.gz http://files.deeppavlov.ai/deeppavlov_data/bert/sentence_ru_cased_L-12_H-768_A-12_pt.tar.gz\n",
        "mkdir -p rubert_sent && tar -C rubert_sent/ -zxvf rubert_sent.tar.gz --strip-components=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VWR3X2lHaFjH",
        "colab": {}
      },
      "source": [
        "def get_rubert_vectors(model, texts):\n",
        "    tokens, token_embs, subtokens, subtoken_embs, sent_max_embs, \\\n",
        "    sent_mean_embs, bert_pooler_outputs = model(texts)\n",
        "    return sent_mean_embs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fP1t3RXiUKc3",
        "colab": {}
      },
      "source": [
        "bert_config = read_json(configs.embedder.bert_embedder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6AOaz-xXUUp_",
        "colab": {}
      },
      "source": [
        "bert_config['metadata']['variables']['BERT_PATH'] = 'rubert_sent/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XWO--9GeUdEh",
        "colab": {}
      },
      "source": [
        "rubert_sent = build_model(bert_config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bY1XOSxvcDl7",
        "outputId": "469454f7-ea2a-4e26-adf5-b888bbfd6d3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "calc_text_rank_score(test_records, calc_sim=cosine_sim, model=rubert_sent, \n",
        "                     get_vecs_f=get_rubert_vectors, tokenize=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count: 1000\n",
            "Ref: в крыму заявили, что угрозы украинских властей отреагировать на запуск поездов по крымскому мосту являются попыткой вмешательства во внутренние дела россии. при этом власти полуострова напомнили, что такие обещания киева пустые, и, как правило, не влекут никаких последствий.\n",
            "Hyp: член комитета совета федерации по международным делам, сенатор от крыма сергей цеков указал, что такой резкий старт свидетельствует об интересе пассажиров к поездкам в крым на железнодорожном транспорте. стоит отметить, что чуть ранее глава республики крым сергей аксенов заявил: инфраструктура полуострова полностью готова к возобновлению железнодорожного сообщения с украиной, теперь решение остается только за киевом. по словам чиновника, республика готова запустить поезда при согласии президента россии владимира путина .\n",
            "BLEU:  0.30728739890818507\n",
            "ROUGE:  {'rouge-1': {'f': 0.15850907546303156, 'p': 0.13916826986068476, 'r': 0.19688784244868618}, 'rouge-2': {'f': 0.03620491586594866, 'p': 0.03179486295088069, 'r': 0.04556089243758258}, 'rouge-l': {'f': 0.131671003817597, 'p': 0.12552458754359114, 'r': 0.17740179774723666}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xdTrfxycB7cd"
      },
      "source": [
        "## Extractive RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1dZamxigdEc-"
      },
      "source": [
        "\n",
        "Implemented approach (except that the sentence encoder GRU were replaced by CNN): https://arxiv.org/pdf/1611.04230.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RBgFOkb4EtsT"
      },
      "source": [
        "### Extractive training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sxsc0Orf8hGq",
        "colab": {}
      },
      "source": [
        "def build_oracle_summary_greedy(text, gold_summary, calc_score, lower=True, max_sentences=30):\n",
        "    gold_summary = gold_summary.lower() if lower else gold_summary\n",
        "    # split text\n",
        "    sentences = [sentence.text.lower() if lower else sentence.text \\\n",
        "                 for sentence in razdel.sentenize(text)][:max_sentences]\n",
        "    n_sentences = len(sentences)\n",
        "    oracle_summary_sentences = set()\n",
        "    score = -1.0\n",
        "    summaries = []\n",
        "    for _ in range(min(n_sentences, 20)):\n",
        "        for i in range(n_sentences):\n",
        "            if i in oracle_summary_sentences:\n",
        "                continue\n",
        "            current_summary_sentences = copy.copy(oracle_summary_sentences)\n",
        "            # add sentences to the generated summary\n",
        "            current_summary_sentences.add(i)\n",
        "            current_summary = \" \".join([sentences[index] \\\n",
        "                                        for index in sorted(list(current_summary_sentences))])\n",
        "            # compute score\n",
        "            current_score = calc_score(current_summary, gold_summary)\n",
        "            summaries.append((current_score, current_summary_sentences))\n",
        "        # if the added sentence improved score, add new sentences (break otherwise)\n",
        "        best_summary_score, best_summary_sentences = max(summaries)\n",
        "        if best_summary_score <= score:\n",
        "            break\n",
        "        oracle_summary_sentences = best_summary_sentences\n",
        "        score = best_summary_score\n",
        "    oracle_sorted = sorted(list(oracle_summary_sentences))\n",
        "    oracle_summary = \" \".join([sentences[index] for index in oracle_sorted])\n",
        "    return oracle_summary, oracle_summary_sentences\n",
        "\n",
        "def calc_single_score(pred_summary, gold_summary, rouge):\n",
        "    return rouge.get_scores([pred_summary], [gold_summary], avg=True)['rouge-2']['f']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7T_ak-KDB8rp",
        "colab": {}
      },
      "source": [
        "def calc_oracle_score(records, nrows=1000, lower=True):\n",
        "    references = []\n",
        "    predictions = []\n",
        "    rouge = Rouge()\n",
        "    calc_f = lambda x, y: calc_single_score(x, y, rouge)\n",
        "  \n",
        "    for text, summary in tqdm(records[['text', 'summary']].values[:nrows]):\n",
        "        summary = summary if not lower else summary.lower()\n",
        "        references.append(summary)\n",
        "        predicted_summary, _ = build_oracle_summary_greedy(text, summary, \n",
        "                                                           calc_score=calc_f)\n",
        "        predictions.append(predicted_summary)\n",
        "\n",
        "    calc_scores(references, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U5HciuS3E1WB",
        "outputId": "b1b5fdc8-9032-443b-8c5f-97def424ce81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "e2c32cbb5e76493eaf157a729e4945e5",
            "c296a36415c24ae99385cde72ad1a1a1",
            "0b72ccfd428e4aabb9f3f52727bf536b",
            "294f6101a1fb4e66b4ed90946877165d",
            "1d0dc70b20f54f46a2483dede6f67c82",
            "cc689ade0a7e4a2296a5abcffd6caaee",
            "885bf4db1c4b44c5a0991ac930e5a2c3",
            "0c7d010a9a884054b57d32c54baf004e"
          ]
        }
      },
      "source": [
        "calc_oracle_score(test_records, nrows=test_records.shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2c32cbb5e76493eaf157a729e4945e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5770.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Count: 5770\n",
            "Ref: обновление ios под номером 13.1.2, призванное решить ряд проблем в системе, лишь прибавило головной боли владельцам iphone — с гаджетов массово сбрасываются звонки, а батарея очень быстро теряет заряд. эксперты рекомендуют не скачивать апдейт, а дождаться, пока apple исправит все недочеты.\n",
            "Hyp: владельцы «яблочных» гаджетов массово жалуются на ряд проблем, которые возникли после того, как на их смартфоны был установлен апдейт ios 13.1.2, сообщает forbes.\n",
            "BLEU:  0.5378135116343372\n",
            "ROUGE:  {'rouge-1': {'f': 0.3718077014808164, 'p': 0.40694068294010777, 'r': 0.36938828858749356}, 'rouge-2': {'f': 0.21086750192505038, 'p': 0.23672926902092492, 'r': 0.20795293543045332}, 'rouge-l': {'f': 0.3254315265705807, 'p': 0.3783154260781943, 'r': 0.34271136213185266}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jdb-39jO-72q",
        "colab": {}
      },
      "source": [
        "def add_oracle_summary_to_records(records, max_sentences=40, lower=True, nrows=1000):\n",
        "    rouge = Rouge()\n",
        "    sentences_ = []\n",
        "    oracle_sentences_ = []\n",
        "    oracle_summary_ = []\n",
        "    records = records.iloc[:nrows].copy()\n",
        "    calc_f = lambda x, y: calc_single_score(x, y, rouge)\n",
        "\n",
        "    for text, summary in tqdm(records[['text', 'summary']].values):\n",
        "        summary = summary.lower() if lower else summary\n",
        "        sentences = [sentence.text.lower() if lower else sentence.text \\\n",
        "                     for sentence in razdel.sentenize(text)][:max_sentences]\n",
        "        oracle_summary, sentences_indicies =\\\n",
        "                    build_oracle_summary_greedy(text, summary, calc_score=calc_f,\n",
        "                    lower=lower, max_sentences=max_sentences)\n",
        "        sentences_ += [sentences]\n",
        "        oracle_sentences_ += [list(sentences_indicies)]\n",
        "        oracle_summary_ += [oracle_summary]\n",
        "    records['sentences'] = sentences_\n",
        "    records['oracle_sentences'] = oracle_sentences_\n",
        "    records['oracle_summary'] = oracle_summary_\n",
        "    return records"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VFQNOHfsDUW6",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XjCz6bLd8npP",
        "colab": {}
      },
      "source": [
        "ext_train_records = add_oracle_summary_to_records(train_records, nrows=train_records.shape[0])\n",
        "ext_train_records.to_pickle('drive/My Drive/train.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rH2IH2rjDeIb",
        "colab": {}
      },
      "source": [
        "ext_val_records = add_oracle_summary_to_records(val_records, nrows=val_records.shape[0])\n",
        "ext_val_records.to_pickle('drive/My Drive/val.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a-d1KGlVDfpv",
        "colab": {}
      },
      "source": [
        "ext_test_records = add_oracle_summary_to_records(test_records, nrows=test_records.shape[0])\n",
        "ext_test_records.to_pickle('drive/My Drive/test.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8PNVc829gd5z",
        "outputId": "b923f836-e811-4e5a-b2ff-f2b186e2009b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "ext_train_records.iloc[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "url                 https://www.gazeta.ru/sport/2011/10/a_3807194....\n",
              "text                После прихода в «Спартак» Марцела Госсы в кома...\n",
              "title                  «Спартаковские болельщики всегда будут роднее»\n",
              "summary             Нападающий «Атланта» Бранко Радивоевич причино...\n",
              "date                                              2011-10-20 01:52:50\n",
              "sentences           [после прихода в «спартак» марцела госсы в ком...\n",
              "oracle_sentences                                              [2, 34]\n",
              "oracle_summary      лишним оказался капитан команды бранко радивое...\n",
              "Name: 28004, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I-g8OTYY-0pN",
        "colab": {}
      },
      "source": [
        "ext_train_records = pd.read_pickle('drive/My Drive/train.pkl')\n",
        "ext_val_records = pd.read_pickle('drive/My Drive/val.pkl')\n",
        "ext_test_records = pd.read_pickle('drive/My Drive/test.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aJpVJGXoE9Bo"
      },
      "source": [
        "### Pretrained BERT model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cl3AkwIsd1WM",
        "colab": {}
      },
      "source": [
        "url = \"http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_pt.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vltlr_6MYEtt",
        "colab": {}
      },
      "source": [
        "%%bash -s \"$url\"\n",
        "wget -O rubert.tar.gz $1\n",
        "mkdir -p rubert && tar -C rubert/ -zxvf rubert.tar.gz --strip-components=1\n",
        "mv rubert/bert_config.json rubert/config.json\n",
        "cp rubert.tar.gz \"drive/My Drive/rubert.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HyL0EwMOEd4k",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "mkdir -p rubert && tar -C rubert/ -zxvf \"drive/My Drive/rubert.tar.gz\" --strip-components=1\n",
        "mv rubert/bert_config.json rubert/config.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vK5oXWI4IM7E",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('rubert')\n",
        "bert = BertForSequenceClassification.from_pretrained('rubert')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SFWhBIB6Fhzu"
      },
      "source": [
        "### Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "14LsQZIC_xLA",
        "colab": {}
      },
      "source": [
        "class ExtDataset(data.Dataset):\n",
        "    def __init__(self, records, tokenizer, lower=True, max_sent=40, \n",
        "                 max_sent_len=50, device=torch.device('cpu')):\n",
        "        self.records = records\n",
        "        self.num_samples = records.shape[0]\n",
        "        self.tokenizer = tokenizer\n",
        "        self.lower = lower\n",
        "        self.rouge = Rouge()\n",
        "        self.max_sent = max_sent\n",
        "        self.max_sent_len = max_sent_len\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        cur_rec = self.records.iloc[idx]\n",
        "        inputs = [tokenizer.encode(sent, max_length=self.max_sent_len) \\\n",
        "                  for sent in cur_rec.sentences]\n",
        "        outputs = [int(i in cur_rec.oracle_sentences) \\\n",
        "                   for i in range(len(cur_rec.sentences))]\n",
        "        return {'inputs': inputs, 'outputs': outputs}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bvARjudojEDD",
        "colab": {}
      },
      "source": [
        "def collate_fn(records):\n",
        "    max_length = max(len(sentence) for record in records for sentence in record['inputs'])\n",
        "    max_sentences = max(len(record['outputs']) for record in records)\n",
        "\n",
        "    new_inputs = torch.zeros((len(records), max_sentences, max_length))\n",
        "    new_outputs = torch.zeros((len(records), max_sentences))\n",
        "    for i, record in enumerate(records):\n",
        "        for j, sentence in enumerate(record['inputs']):\n",
        "            new_inputs[i, j, :len(sentence)] += np.array(sentence)\n",
        "        new_outputs[i, :len(record['outputs'])] += np.array(record['outputs'])\n",
        "    return {'features': new_inputs.type(torch.LongTensor), 'targets': new_outputs}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A1w5mK3U00SJ",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "TRAIN_SIZE = 5000\n",
        "VALID_SIZE = 500\n",
        "\n",
        "train_loaders = {\n",
        "    'train': data.DataLoader(ExtDataset(ext_train_records.iloc[:TRAIN_SIZE, :], tokenizer), \n",
        "                             batch_size=BATCH_SIZE, collate_fn=collate_fn, \n",
        "                             shuffle=True),\n",
        "    'valid': data.DataLoader(ExtDataset(ext_val_records.iloc[:VALID_SIZE, :], tokenizer), \n",
        "                             batch_size=BATCH_SIZE, collate_fn=collate_fn)}\n",
        "test_loader = data.DataLoader(ExtDataset(ext_test_records.iloc[:VALID_SIZE, :], tokenizer), \n",
        "                              batch_size=1, collate_fn=collate_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UlXXc8qUHC5m"
      },
      "source": [
        "\n",
        "### SummaRuNNer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "djVAIAuxGAEx"
      },
      "source": [
        "#### Sentence encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L-ZaWKJjn_B1",
        "colab": {}
      },
      "source": [
        "def cnn_block(in_channels, out_channels, kernel, n=2):\n",
        "    layers = []\n",
        "    for _ in range(n):\n",
        "        conv = nn.Conv1d(in_channels, out_channels, kernel)\n",
        "        bn = nn.BatchNorm1d(out_channels)\n",
        "        layers += [conv, bn, nn.LeakyReLU(inplace=True)]\n",
        "        in_channels = out_channels\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d5t-8Vds6XjK",
        "colab": {}
      },
      "source": [
        "class SentenceEncoderCNN(nn.Module):\n",
        "    def __init__(self, emb_layer, emb_dim, out_c, kernels):\n",
        "        super(SentenceEncoderCNN, self).__init__()\n",
        "        self.emb_dim = emb_dim\n",
        "        self.out_c = out_c\n",
        "        self.embedding = emb_layer\n",
        "        self.convs = nn.ModuleList([cnn_block(self.emb_dim, self.out_c, kernel) \\\n",
        "                                  for kernel in kernels])\n",
        "    def forward(self, inputs):\n",
        "        # [B x Len x Emb] to [B x Emb x Len] (for conv by len)\n",
        "        emb = F.dropout(self.embedding(inputs), p=0.2).permute((0, 2, 1))\n",
        "        n_gram_emb = []\n",
        "        for conv in self.convs:\n",
        "            new_emb = conv(emb) # [B x out_c x (Len - out_c) / stride + 1]\n",
        "            # [B x out_c x 1]\n",
        "            new_emb = F.max_pool1d(new_emb, new_emb.size(2)).squeeze(2)\n",
        "            n_gram_emb += [new_emb]\n",
        "        n_gram_emb = torch.cat(n_gram_emb, 1).view(-1, self.emb_dim, len(self.convs))\n",
        "        return F.avg_pool1d(n_gram_emb, n_gram_emb.size(2)).squeeze(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TH_-XbO1GELV"
      },
      "source": [
        "#### Sentence tagger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3SU0Q7aSCupR",
        "colab": {}
      },
      "source": [
        "class SentenceTaggerRNN(nn.Module):\n",
        "    def __init__(self, emb_layer, kernels, hid_dim=768, bidirect=True, \n",
        "                 max_sent_len=50, n_segments=10, pos_emb_dim=5):\n",
        "        super(SentenceTaggerRNN, self).__init__()\n",
        "        \n",
        "        tok_emb_dim = emb_layer.weight.shape[1]\n",
        "        # for cat without pooling tok_emb_dim - tok_emb_dim % len(kernels)\n",
        "        sent_enc_hid_dim = tok_emb_dim\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_dir = bidirect + 1\n",
        "        self.max_sent_len = max_sent_len\n",
        "        self.n_segments = n_segments\n",
        "\n",
        "        # for cat without pooling sent_enc_hid_dim // len(kernels)\n",
        "        self.sent_enc = SentenceEncoderCNN(emb_layer, tok_emb_dim, \n",
        "                                           tok_emb_dim, kernels)                                 \n",
        "        self.rnn = nn.GRU(sent_enc_hid_dim, hid_dim, bidirectional=bidirect, \n",
        "                          batch_first=True)\n",
        "        \n",
        "        self.doc_layer = nn.Linear(self.hid_dim, self.hid_dim)\n",
        "        self.content = nn.Linear(self.hid_dim, 1, bias=False)\n",
        "        self.salience = nn.Bilinear(self.hid_dim, self.hid_dim, 1, bias=False)\n",
        "        self.novelty = nn.Bilinear(self.hid_dim, self.hid_dim, 1, bias=False)\n",
        "\n",
        "        self.abs_pos_emb = nn.Embedding(max_sent_len, pos_emb_dim)\n",
        "        self.rel_pos_emb = nn.Embedding(n_segments, pos_emb_dim)\n",
        "\n",
        "        self.abs_pos = nn.Linear(pos_emb_dim, 1, bias=False)\n",
        "        self.rel_pos = nn.Linear(pos_emb_dim, 1, bias=False)\n",
        "        self.bias = nn.Parameter(torch.FloatTensor(1).uniform_(-0.1, 0.1))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        batch_size, n_sent, n_tokens = inputs.size()\n",
        "        # to [Batch * Doc_len x Sent_len]\n",
        "        inputs = inputs.view(-1, n_tokens)\n",
        "        # [Batch * Doc_len x Hid_dim] to [B x Doc_Len x Hid_dim]\n",
        "        sent_emb = self.sent_enc(inputs).view(batch_size, n_sent, -1)\n",
        "\n",
        "        # [B x Doc_len x Hid_dim * n_directions] to [B x Doc_len x n_directions x Hid_dim]\n",
        "        sent_emb = self.rnn(sent_emb)[0].view(batch_size, n_sent, self.n_dir, -1)\n",
        "        sent_emb = F.dropout(sent_emb, p=0.2)\n",
        "\n",
        "        # mean by directions, [B x Doc_len x Hid_dim]\n",
        "        avg_sent_emb = torch.mean(sent_emb, dim=2)\n",
        "        # mean by document len, expand for compability with @avg_sent_emb\n",
        "        doc_emb = torch.mean(avg_sent_emb, dim=1, keepdim=True).expand(batch_size, n_sent, -1)\n",
        "\n",
        "        # total document representation, [B x Doc_len x Hid_dim]\n",
        "        D = torch.tanh(self.doc_layer(doc_emb))\n",
        "\n",
        "        # initial summary state\n",
        "        h0 = torch.zeros((batch_size, 1, self.hid_dim), device=DEVICE)\n",
        "        # partial summary representations (except very last sentence)\n",
        "        S = torch.cumsum(avg_sent_emb[:, :-1], dim=1)\n",
        "        S = torch.cat((h0, S), dim=1)\n",
        "\n",
        "        content = self.content(avg_sent_emb).squeeze(2)\n",
        "        salience = self.salience(avg_sent_emb, D).squeeze(2)\n",
        "        novelty = -1 * self.novelty(avg_sent_emb, torch.tanh(S)).squeeze(2)\n",
        "\n",
        "        pos_idx = torch.arange(n_sent, dtype=torch.long, device=DEVICE).expand(batch_size, n_sent)\n",
        "        abs_emb = self.abs_pos_emb(pos_idx)\n",
        "        rel_emb = self.rel_pos_emb(pos_idx // self.n_segments)\n",
        "\n",
        "        abs_p = self.abs_pos(abs_emb).squeeze(2)\n",
        "        rel_p = self.rel_pos(abs_emb).squeeze(2)\n",
        "\n",
        "        return content + salience + novelty + abs_p + rel_p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7Ued4l-WWVd1",
        "colab": {}
      },
      "source": [
        "kernels = [2, 3, 5, 7]\n",
        "tagger = SentenceTaggerRNN(bert.get_input_embeddings(), kernels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4q2Gb6ODHHB_"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GNjxoAJpsVby",
        "colab": {}
      },
      "source": [
        "lr = 1e-4\n",
        "num_epochs = 10\n",
        "\n",
        "optimizer = torch.optim.Adam(tagger.parameters(), lr=lr)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "runner = SupervisedRunner(device=DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UVDW8raJeQxn",
        "outputId": "fc656c2e-3c7c-47d7-c488-39122ef92042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "runner.train(\n",
        "    model=tagger,\n",
        "    optimizer=optimizer,\n",
        "    loaders=train_loaders,\n",
        "    logdir='./logs',\n",
        "    num_epochs=num_epochs,\n",
        "    criterion=criterion,\n",
        "    verbose=True,\n",
        "    load_best_on_end=True,\n",
        "    callbacks=[EarlyStoppingCallback(patience=3)]\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/10 * Epoch (train): 100% 157/157 [04:32<00:00,  1.74s/it, loss=0.233]\n",
            "1/10 * Epoch (valid): 100% 16/16 [00:17<00:00,  1.08s/it, loss=0.269]\n",
            "[2020-05-27 02:46:09,553] \n",
            "1/10 * Epoch 1 (_base): lr=0.0001 | momentum=0.9000\n",
            "1/10 * Epoch 1 (train): loss=0.7252\n",
            "1/10 * Epoch 1 (valid): loss=0.2987\n",
            "2/10 * Epoch (train): 100% 157/157 [04:29<00:00,  1.72s/it, loss=0.249]\n",
            "2/10 * Epoch (valid): 100% 16/16 [00:17<00:00,  1.08s/it, loss=0.229]\n",
            "[2020-05-27 02:52:50,531] \n",
            "2/10 * Epoch 2 (_base): lr=0.0001 | momentum=0.9000\n",
            "2/10 * Epoch 2 (train): loss=0.3877\n",
            "2/10 * Epoch 2 (valid): loss=0.2485\n",
            "3/10 * Epoch (train): 100% 157/157 [04:29<00:00,  1.72s/it, loss=0.117]\n",
            "3/10 * Epoch (valid): 100% 16/16 [00:17<00:00,  1.08s/it, loss=0.259]\n",
            "[2020-05-27 02:59:33,915] \n",
            "3/10 * Epoch 3 (_base): lr=0.0001 | momentum=0.9000\n",
            "3/10 * Epoch 3 (train): loss=0.2245\n",
            "3/10 * Epoch 3 (valid): loss=0.2773\n",
            "4/10 * Epoch (train): 100% 157/157 [04:29<00:00,  1.72s/it, loss=0.226]\n",
            "4/10 * Epoch (valid): 100% 16/16 [00:17<00:00,  1.08s/it, loss=0.201]\n",
            "[2020-05-27 03:05:27,449] \n",
            "4/10 * Epoch 4 (_base): lr=0.0001 | momentum=0.9000\n",
            "4/10 * Epoch 4 (train): loss=0.2125\n",
            "4/10 * Epoch 4 (valid): loss=0.2223\n",
            "5/10 * Epoch (train): 100% 157/157 [04:32<00:00,  1.73s/it, loss=0.185]\n",
            "5/10 * Epoch (valid): 100% 16/16 [00:17<00:00,  1.08s/it, loss=0.187]\n",
            "[2020-05-27 03:12:12,039] \n",
            "5/10 * Epoch 5 (_base): lr=0.0001 | momentum=0.9000\n",
            "5/10 * Epoch 5 (train): loss=0.2023\n",
            "5/10 * Epoch 5 (valid): loss=0.2275\n",
            "6/10 * Epoch (train): 100% 157/157 [04:30<00:00,  1.72s/it, loss=0.175]\n",
            "6/10 * Epoch (valid): 100% 16/16 [00:17<00:00,  1.10s/it, loss=0.211]\n",
            "[2020-05-27 03:18:05,602] \n",
            "6/10 * Epoch 6 (_base): lr=0.0001 | momentum=0.9000\n",
            "6/10 * Epoch 6 (train): loss=0.1737\n",
            "6/10 * Epoch 6 (valid): loss=0.2462\n",
            "7/10 * Epoch (train): 100% 157/157 [04:33<00:00,  1.74s/it, loss=0.163]\n",
            "7/10 * Epoch (valid): 100% 16/16 [00:17<00:00,  1.11s/it, loss=0.288]\n",
            "[2020-05-27 03:24:02,698] \n",
            "7/10 * Epoch 7 (_base): lr=0.0001 | momentum=0.9000\n",
            "7/10 * Epoch 7 (train): loss=0.1200\n",
            "7/10 * Epoch 7 (valid): loss=0.3147\n",
            "Early stop at 7 epoch\n",
            "Top best models:\n",
            "logs/checkpoints/train.4.pth\t0.2223\n",
            "=> Loading checkpoint logs/checkpoints/best_full.pth\n",
            "loaded state checkpoint logs/checkpoints/best_full.pth (global epoch 4, epoch 4, stage train)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8VJeta1b5CtD",
        "outputId": "cbb41205-60bc-41a6-da73-912a49ce6ad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "03d9bf261d004f42a670d5d48af74dd8",
            "07f11d207f694a1c9dd3b9ef4eca2481",
            "17aca299d82b4d04b98c569ef439e388",
            "63ff5d22e2f04c718a75b53736fedaf8",
            "c84df55980af4f28a6868f3844fecde7",
            "b27cae5003554d6787a883877c4bc1fc",
            "a1d8f749f19f4c9380915805d0fdbc6c",
            "be3beace13f8465191ce20ef343923fb"
          ]
        }
      },
      "source": [
        "references = []\n",
        "predictions = []\n",
        "threshold_prob = 0.2\n",
        "tagger.eval()\n",
        "with torch.no_grad():\n",
        "    for i, item in tqdm(enumerate(test_loader), total=VALID_SIZE):\n",
        "        probs = torch.sigmoid(tagger(item['features'].to(DEVICE)))[0]\n",
        "        record = ext_test_records.iloc[i]\n",
        "        predicted_summary = []\n",
        "        sorted_p, sorted_i = torch.sort(probs, descending=True)\n",
        "        for (prob, i) in zip(sorted_p, sorted_i):\n",
        "            if prob < threshold_prob:\n",
        "                break\n",
        "            predicted_summary.append(record['sentences'][i])\n",
        "        if not predicted_summary:\n",
        "            predicted_summary.append(record['sentences'][sorted_i[0]])\n",
        "        predicted_summary = ' '.join(predicted_summary)\n",
        "        references.append(record['summary'].lower())\n",
        "        predictions.append(predicted_summary)\n",
        "\n",
        "    calc_scores(references, predictions)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03d9bf261d004f42a670d5d48af74dd8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Count: 500\n",
            "Ref: ученые выяснили, откуда взялись ровные трещины на поверхности энцелада, спутника сатурна. спутник пострадал из-за собственных приливов, которые испытывает, вращаясь по орбите.\n",
            "Hyp: американские ученые разгадали загадку одного из самых необычных тел солнечной системы — энцелада.\n",
            "BLEU:  0.4207066727688847\n",
            "ROUGE:  {'rouge-1': {'f': 0.237196947948618, 'p': 0.27462540643633476, 'r': 0.2343851245459358}, 'rouge-2': {'f': 0.09782887887790095, 'p': 0.11505677857292236, 'r': 0.09754047857158932}, 'rouge-l': {'f': 0.19459520396188398, 'p': 0.24654315261738127, 'r': 0.2099648816565591}}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}